{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tm_Img.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "rcVTE2seJLh-",
        "0RrZ60pOLMLf",
        "YGA5T8CWJUeQ",
        "clWNPjGlKRaB"
      ]
    },
    "kernelspec": {
      "name": "python37364bitc95d52f24ee949bb87971233c05b3db5",
      "display_name": "Python 3.7.3 64-bit"
    },
    "metadata": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4wmAFyNDX8h",
        "outputId": "76606e39-c007-43e1-cc21-1dd55b9c779d"
      },
      "source": [
        "import tensorflow.keras\n",
        "from PIL import Image, ImageOps\n",
        "import numpy as np\n",
        "\n",
        "# Disable scientific notation for clarity\n",
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "# Load the model\n",
        "model = tensorflow.keras.models.load_model('Modelo/keras_model.h5')\n",
        "\n",
        "# Create the array of the right shape to feed into the keras model\n",
        "# The 'length' or number of images you can put into the array is\n",
        "# determined by the first position in the shape tuple, in this case 1.\n",
        "data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
        "\n",
        "# Replace this with the path to your image\n",
        "image = Image.open('uploads/pina-2.jpg')\n",
        "\n",
        "#resize the image to a 224x224 with the same strategy as in TM2:\n",
        "#resizing the image to be at least 224x224 and then cropping from the center\n",
        "size = (224, 224)\n",
        "image = ImageOps.fit(image, size, Image.ANTIALIAS)\n",
        "\n",
        "#turn the image into a numpy array\n",
        "image_array = np.asarray(image)\n",
        "\n",
        "# display the resized image\n",
        "image.show()\n",
        "\n",
        "# Normalize the image\n",
        "normalized_image_array = (image_array.astype(np.float32) / 127.0) - 1\n",
        "\n",
        "# Load the image into the array\n",
        "data[0] = normalized_image_array\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'uploads/pina-2.jpg'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-28faa17e7da6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Replace this with the path to your image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uploads/pina-2.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#resize the image to a 224x224 with the same strategy as in TM2:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/Library/Python/3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2877\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2878\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2879\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'uploads/pina-2.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcVTE2seJLh-"
      },
      "source": [
        "# Prediccion\n",
        "## Se imprime el arreglo de la prediccion "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdbLSqbzM5vQ"
      },
      "source": [
        "prediction = model.predict(data)\n",
        "print(prediction[0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.988986   0.00140615 0.00960781]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RrZ60pOLMLf"
      },
      "source": [
        "## Determinar la categoria "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "OFEe3r9hE236",
        "outputId": "1d6f36f3-41ee-409b-af25-39fa7c62ff94"
      },
      "source": [
        "# Find index of maximum value from 2D numpy array\n",
        "max_value = np.amax(prediction)\n",
        "max_index = np.where(prediction == np.amax(prediction))\n",
        "print('Tuple of arrays returned : ', max_index)\n",
        "indice = max_index[1]\n",
        "\n",
        "'''\n",
        "# Obtener las coordenadas del indice de maximo lelento en el NUMPAY ARRAY\n",
        "print('List of coordinates of maximum value in Numpy array : ')\n",
        "# zip the 2 arrays to get the exact coordinates\n",
        "listOfCordinates = list(zip(result[0], result[1]))\n",
        "# travese over the list of cordinates\n",
        "for cord in listOfCordinates:\n",
        "    print(cord)\n",
        "'''"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tuple of arrays returned :  (array([0]), array([0]))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# Obtener las coordenadas del indice de maximo lelento en el NUMPAY ARRAY\\nprint('List of coordinates of maximum value in Numpy array : ')\\n# zip the 2 arrays to get the exact coordinates\\nlistOfCordinates = list(zip(result[0], result[1]))\\n# travese over the list of cordinates\\nfor cord in listOfCordinates:\\n    print(cord)\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sif77kI1H6Cy",
        "outputId": "32903384-8850-4236-849f-1d5715b73650"
      },
      "source": [
        "text_file = open(\"Modelo/labels.txt\", \"r\") \n",
        "labels = text_file.readlines()\n",
        "labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGA5T8CWJUeQ"
      },
      "source": [
        "## Se imprime la mayor probabilidad y su etiqueta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cgHYxDfINyW",
        "outputId": "8504b183-768f-491c-be42-9cbb437de4cd"
      },
      "source": [
        "print(labels[int(max_index[1])]+\" = \"+str(max_value))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 Pina\n = 0.988986\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clWNPjGlKRaB"
      },
      "source": [
        "# Ejecucion de la logica de control de acuerdo a los casos (opcional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVCzcM5ZKbwq",
        "outputId": "3a243b2f-773f-4887-f309-7013eb09a2df"
      },
      "source": [
        "if (int(max_index[1])==0):\n",
        "  print(\"Abre compuerta pera\")\n",
        "elif (int(max_index[1])==1):\n",
        "  print(\"Abre compuerta fresa\")\n",
        "elif (int(max_index[1])==2):\n",
        "  print(\"Abre compuerta pi√±a\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Abre compuerta pera\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def model_predict(img_path, model):\n",
        "    image = Image.open(img_path)\n",
        "    size = (224, 224)\n",
        "    image = ImageOps.fit(image, size, Image.ANTIALIAS)\n",
        "\n",
        "    # turn the image into a numpy array\n",
        "    image_array = np.asarray(image)\n",
        "\n",
        "    # Normalize the image\n",
        "    normalized_image_array = (image_array.astype(np.float32) / 127.0) - 1\n",
        "\n",
        "    # Load the image into the array\n",
        "    data[0] = normalized_image_array\n",
        "\n",
        "    # run the inference\n",
        "    preds = model.predict(data)\n",
        "    return preds[0]"
      ]
    },
    {
      "source": [
        "## Pruebas de escritorio"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.00067635 0.00009484 0.99922884]\nTuple of arrays returned :  (array([2]),)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "pred = model_predict('uploads/test.jpg', model)\n",
        "print(pred)\n",
        "max_value = np.amax(pred)\n",
        "max_index = np.where(pred == np.amax(pred))\n",
        "print('Tuple of arrays returned : ', max_index)\n",
        "indice = max_index[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "max_index = np.where(pred == np.amax(pred))\n",
        "max_index[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2 Fresa\\n = 0.99922884'"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "predText = str(labels[int(max_index[0][0])]+\" = \"+str(max_value))\n",
        "predText"
      ]
    }
  ]
}